


Deep neural networks promise to significantly enhance a wide range of important tasks in biomedical imaging. However these models, as typically used, lack formal uncertainty guarantees on their output which can lead to overconfident predictions and critical errors. Misclassifications or inaccurate segmentations can lead to serious consequences, including misdiagnosis, inappropriate treatment decisions, or missed opportunities for early intervention.  As a consequence, despite their potential utility, medical professionals cannot yet rely on deep learning models to provide accurate information and predictions which greatly limits their use in practical applications. 
%As these models are increasingly deployed in critical real-world scenarios quantifying the uncertainty associated with their predictions is a significant challenge.

In order to address this problem, conformal inference, a robust framework for uncertainty quantification, has become increasingly used as a means of providing prediction guarantees, offering reliable, distribution-free confidence sets for the output of neural networks which have finite sample validity. This approach, originally introduced in XXX, has become increasingly popular (CITE) due to its ability to provide rigorous statistical guarantees without making strong assumptions about the underlying data distribution or model architecture. Conformal prediction methods, in their most commonly used form - split conformal inference - work by calibrating the predictions of the model on a held-out dataset in order to provide sets which contain the output with a given probability, see \cite{Angelopoulos2021} for a good introduction.

In the context of image segmentation, we have a decision to make at each pixel/voxel of an image which can lead to a large multiple testing problem. Traditional conformal methods, typically designed for scalar outputs, require adaptation to handle multiple tests and their inherent spatial dependencies. \cite{Angelopoulos2021LTT} applied conformal inference pixelwise and performed multiple testing correction on the resulting $p$-values, however this approach does not take into account of the complex dependence structure inherent in the images. Instead, in an approach analogous to FDR control \citep{Benjamini1995}, \cite{Bates2021} and \cite{Angelopoulos2022} sought to control the expected risk of a given loss function over the image and used a conformal approach to produce confidence sets for segmented images which control the expected false negative rate. XXX instead targetted bounding boxes for the image which. Other work considering conformal inference in the context of multiple dependent hypotheses include XXX and XXX who established conformal FDR control when testing for the presence of missing links in graphs. Under exchangability of the considered hypotheses XXX provides false coverage rate control over multiple conformal inferences.

In this work we argue that bounding the segmented outcome with guarantees in probability rather than in expectation/proportion can be more informative, avoiding errors at the borders of potential tumors. This is analogous to the tradeoff between FWER and FDR/FDP control in the multiple testing literature in which there is a balance between power and coverage rate, the distinction being that in medical image segmentation there can be a potentially serious consequence to making mistakes. Under-segmentation might cause part of the tumor to be missed, potentially leading to inadequate treatment. Over-segmentation, on the other hand, could result in unnecessary interventions, increasing patient risk and healthcare costs. Unlike bounds on the proportion of discovered pixels/voxels, coverage bounds are guaranteed to contain the outcome with a given level of confidence and allow doctors to follow-up on the images where there is more uncertainty. Since the guarantees are more meaningful the problem is more difficult and so the resulting confidence bounds are larger. To address this, as we shall show, score transformations are required in order to improve precision. 

In order to obtain confidence sets we use a split-conformal inference approach in which we learn appropriate cutoffs, with which to threshold the output of an image segementer, from a calibration dataset. These thresholds are obtained by considering the distribution of the maximum logit (transformed) scores provided by the model within and outside of the ground truth masks. This approach allows us to capture the spatial nature of the uncertainty in segmentation tasks, going beyond simple pixel-wise confidence measures. By applying these learned thresholds to new predictions, we can generate confidence sets that are guaranteed to contain the true, unknown segmented mask with a desired probability. 

The confidence sets we develop in this paper are related in spirit to work on uncertainty quantification for spatial excursion sets (\cite{Bowring2019}, \cite{Mejia2019}, CHEN). These approaches instead assume that multiple observations from a signal plus noise model are observed and perform inference on the underlying signal rather than prediction, obtaining confidence regions with asymptotic coverage guarantees. These confidence regions have been applied in neurosimaging \citep{Bowring2019} and climite data \cite{Ren} to provide uncertainty for the location of activation above a pre-specified threshold. 


In the following sections, we will explore the technical details of our method, present our theoretical results, and provide a comprehensive evaluation and demonstration of our approach across various biomedical imaging scenarios. In particular Section XXX provides the theory for constructing joint and marginal conformal confidence sets and includes an extension to full conformal inference. We provide theoretical guarantees on the coverage properties of our confidence sets, ensuring their reliability across different datasets and segmentation models. Section XXX shows that confidence sets can also be obtained using concentration inequalities by adapting the results of XXX to our setting. In Section XXX, we apply our methodology to three distinct medical imaging settings, demonstrating that our approach consistently achieves the correct level of coverage while also proving to be both practical and informative.
  
