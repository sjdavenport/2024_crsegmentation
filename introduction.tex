


Deep neural networks promise to significantly enhance a wide range of important tasks in biomedical imaging. However these models, as typically used, lack formal uncertainty guarantees on their output which can lead to overconfident predictions and critical errors. Misclassifications or inaccurate segmentations can lead to serious consequences, including misdiagnosis, inappropriate treatment decisions, or missed opportunities for early intervention. As a consequence, despite their potential utility, medical professionals cannot yet rely on deep learning models to provide accurate information and predictions which greatly limits their use in practical applications. 
%As these models are increasingly deployed in critical real-world scenarios quantifying the uncertainty associated with their predictions is a significant challenge.

In order to address this problem, conformal inference, a robust framework for uncertainty quantification, has become increasingly used as a means of providing prediction guarantees, offering reliable, distribution-free confidence sets for the output of neural networks which have finite sample validity. This approach, originally introduced in XXX, has become increasingly popular due to its ability to provide rigorous statistical guarantees without making strong assumptions about the underlying data distribution or model architecture. Conformal inference methods work by calibrating the predictions of the model on a held-out dataset, allowing for the construction of confidence sets which contain the true outcome with a given probability, see XXX for a good introduction. 

In the context of image segmentation, we have a test at each pixel/voxel of an image leading to a large multiple testing problem. As such traditional conformal methods, typically designed for scalar or low-dimensional outputs, require adaptation to handle the inherent spatial dependencies. and multiple tests. XXX applied conformal inference pixelwise and applied multiple testing corrections to the resulting p-values, however this approach does not take into account the complex dependence structure inherent in the images. In an approach analogous to the FDR correction which is popular in the multiple testing litereature, XXX instead sought to control the expected risk of a given loss function over the image and used a conformal approach to produce confidence sets for segmented images which control the expected false negative rate. 

We will argue in this work that it . This is analogous to the tradeoff between FWER and FDR control in the multiple testing literature. Whilst ex. In the context of medical imaging we will argue that knowing the outcome with guarantees in probability rather than in expectation is more helpful, avoiding errors at the borders of potential tumors and allowing doctors to follow-up on the images where there is less certainty.


Our work extends the conformal inference framework to the imaging domain and addressing the specific nuances of uncertainty quantification in image segmentation models.

Image segmentation is a particularly important task in biomedical imaging where accurate delineation of anatomical structures and pathological regions is crucial for diagnosis, treatment planning, and patient care. Over the past 10 years deep learning models have demonstrated remarkable performance in tackling image segmentation challenges, often surpassing traditional methods and, in some cases, even rivaling human expertise CITE UNET. In 


In this paper, we develop confidence sets which offer spatial uncertainty guarantees for black-box image segmentation models. Our method builds upon the framework of conformal inference, a powerful statistical technique for constructing prediction sets with guaranteed coverage probabilities. We adapt this approach to the specific challenges posed by the imaging setting, where the output space is high-dimensional and structured.


The core of our innovation lies in learning appropriate thresholds on a calibration dataset, based on the distribution of the maximum logit scores provided by the model outside of the ground truth masks. This approach allows us to capture the spatial nature of the uncertainty in segmentation tasks, going beyond simple pixel-wise confidence measures. By applying these learned thresholds to new predictions, we can generate confidence sets that are guaranteed to contain the true, unknown segmented mask with a desired probability.

Our work makes several key contributions to the field:

We present a principled method for quantifying spatial uncertainty in image segmentation tasks, addressing a critical gap in the current literature.
We provide theoretical guarantees on the coverage properties of our confidence sets, ensuring their reliability across different datasets and segmentation models.
We demonstrate the practical applicability and effectiveness of our approach through extensive experiments on a diverse range of biomedical imaging applications, including polyp segmentation from colonoscopy scans, brain image segmentation, and melanoma delineation.
We offer insights into the relationship between model confidence and segmentation accuracy, potentially guiding future improvements in segmentation algorithms and model calibration techniques.

The significance of our work extends beyond the immediate technical contributions. By providing a rigorous framework for uncertainty quantification in image segmentation, we pave the way for more responsible and interpretable deployment of AI in critical domains. In medical imaging, for instance, our method could enable clinicians to make more informed decisions by highlighting regions of high uncertainty that may require additional scrutiny or alternative diagnostic procedures.

Furthermore, our approach has the potential to enhance the overall reliability and trustworthiness of AI-assisted image analysis systems. By clearly delineating the limits of model certainty, we can help prevent overconfidence in automated predictions and promote a more nuanced integration of AI tools into professional workflows.

As we continue to witness the rapid advancement of deep learning techniques in computer vision, the need for robust uncertainty quantification methods becomes increasingly paramount. Our work represents a significant step forward in this direction, offering a powerful tool for researchers and practitioners alike to assess and communicate the spatial uncertainty inherent in image segmentation tasks.

In the following sections, we will delve into the technical details of our method, present our theoretical results, and provide a comprehensive evaluation of our approach across various biomedical imaging scenarios. We will also discuss the broader implications of our work and outline promising directions for future research in this critical area of machine learning and computer vision.

The confidence sets developed in this work are partially motivated by recent work by \cite{Sommerfield2018} who developed confidence regions for the location and magnitude of brain activation above a pre-chosen threshold with applications to climate data and to neuroimaging \citep{Bowring2019, Bowring2020},  

 advancements in the field of spatial, particularly in the development of methods which address the limitations of traditional hypothesis testing. In particular Sommerfeld et al. (2018), developed confidence sets. 

which was extended by subsequent research to improve spatial inference in fMRI studies. These studies have highlighted significant challenges in neuroimaging, such as the potential for universal brain activation after hypothesis testing, even under stringent correction methods, as demonstrated by Gonzalez-Castillo et al. (2012). The concerns raised in these studies about the misuse of p-values and the limitations of traditional statistical inference have led to the development of alternative methods that focus on providing more robust confidence estimates for spatial data.

One of the most notable contributions in this area is the development of spatial confidence sets (CSs) that allow for inference on non-zero raw effect sizes in neuroimaging data. The work by Sommerfeld et al. (2018), and its extensions, proposed a method for constructing CSs that provide confidence guarantees about  These CSs offer a significant advantage over traditional voxelwise thresholding by enabling researchers to make precise confidence statements about where activation occurs in the brain, rather than simply determining whether it is present. The method's ability to offer these guarantees in the context of complex, high-dimensional data, such as fMRI, is particularly relevant to our work in image segmentation.