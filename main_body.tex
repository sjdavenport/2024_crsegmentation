\section{Theory}
\subsection{Set up}
Let $\mathcal{V} \subset \mathbb{R}^m$, for some dimension $m \in \mathbb{N}$, be a finite set corresponding to the domain which represents the pixels/voxels at which we observe imaging data. Let $\mathcal{X} = \lbrace g: \mathcal{V} \rightarrow \mathbb{R}\rbrace$ be the set of real functions on $\mathcal{V}$ and let $\mathcal{Y} = \lbrace g: \mathcal{V} \rightarrow \lbrace 0,1 \rbrace \rbrace$ be the set of all functions taking the values 0 or 1. We shall refer to elements of $\mathcal{X}$ and $\mathcal{Y}$ as images. Suppose that we observe a calibration dataset $(X_i, Y_i)_{i = 1}^n$ of random images, where $X_i: \mathcal{V} \rightarrow \mathbb{R}$ represents the $i$th observed calibration image and $Y_i:\mathcal{V} \rightarrow \lbrace 0, 1\rbrace$ outputs labels at each $v \in \mathcal{V}$ giving 1s at the true location of the objects in the image $X_i$ that we wish to identify and 0s elsewhere. Let $\mathcal{P}(\mathcal{V})$ be the set of all subsets of $\mathcal{V}$. Moreover, given a function $f:\mathcal{X} \rightarrow \mathcal{X}$, we shall write $f(X,v)$ to denote $f(X)(v)$ for all $v \in \mathcal{V}$. 

Let $s:\mathcal{X}  \rightarrow \mathcal{X} $ be a score function - trained on an independent dataset - such that given an image pair $(X,Y) \in \mathcal{X}\times \mathcal{Y}$, $s(X)$ is a score image in which $s(X,v) $ is intended to be higher at the $v \in \mathcal{V}$ for which $Y(v) = 1$. The score function can for instance be the logit scores obtained from a deep neural network image segmentation method to the image $X$ as input e.g. CITE. Given $X \in \mathcal{X}$, let $\hat{M}(X) \in \mathcal{Y}$ be the predicted mask based on the segmentation model. I.e. let $M(X,v) = 1$ if $s(X,v) > 0.5$ and 0 otherwise for each $v \in \mathcal{V}.$
%Let $T(Y) = \left\lbrace v\in \mathcal{V}: Y(v) = 1 \right\rbrace$ correspond to the true location of the objects in the image $X$. 

In what follows we will use the calibration dataset to construct a confidence functions $I,O:  \mathcal{X}  \rightarrow \mathcal{P}(\mathcal{V})$ such that for a new image pair $(X,Y) \sim \mathcal{D}$, given error rates $\alpha_1, \alpha_2 \in (0,1)$ we have
\begin{equation}\label{eq:probstat1}
	\mathbb{P}\left( I(X) \subseteq \lbrace v\in \mathcal{V}: Y(v) = 1 \rbrace  \right) \geq 1 - \alpha_1, 
\end{equation}
\begin{equation}\label{eq:probstat2}
	\text{ and } 	\mathbb{P}\left( \lbrace v\in \mathcal{V}: Y(v) = 1 \rbrace \subseteq O(X)  \right) \geq 1 - \alpha_2.
\end{equation}
Here $I(X)$ and $O(X)$ serve as inner and outer confidence sets for the location of the true segmented mask. Their interpretation is that, up to the guarantees provided by the probabilistic statements \eqref{eq:probstat1} and \eqref{eq:probstat2}, we can be sure that for each $v\in I(X)$, $Y(v) = 1$ or that for each $v \not\in O(X)$, $Y(v) = 0$. See Figure \ref{fig:polpys} for an example of this in practice. Joint control over the events can also be guaranteed, either by sensible choices of $\alpha_1$ and $\alpha_2$ or by using the joint distribution of the maxima of the logit scores - see Section \ref{SS:joint}. 

In order to establish conformal confidence results we shall require the following exchangeablity assumption. 
\begin{assumption}\label{ass:ex}
		Given a new random image pair, $(X_{n+1},Y_{n+1})$, suppose that $(X_i, Y_i)_{i = 1}^{n+1}$ is an exchangeable sequence of random image pairs in the sense that 
	\begin{equation*}
		\left\lbrace (X_1,Y_1), \dots, (X_{n+1}, Y_{n+1}) \right\rbrace =_d \left\lbrace (X_{\sigma(1)}, Y_{\sigma(1)}), \dots, (X_{\sigma(n+1)}, Y_{\sigma(n+1)}) \right\rbrace
	\end{equation*}
	for any permutation $\sigma \in S_{n+1}$. Here $=_d$ denotes equality in distribution and $S_{n+1} $ is the group of permutations of the integers $\lbrace1, \dots, n+1\rbrace$.
\end{assumption}
Exchangeability or a variant is a standard assumption in the conformal inference literature \citep{Angelopoulos2021} and factilates coverage guarantees. It holds for instance if we assume that the collection $(X_i, Y_i)_{i = 1}^{n+1}$ is an i.i.d. sequence of image pairs but is more general and in principle allows for other dependence structures. 

\subsection{Marginal confidence sets}\label{SS:MCS}
In order to construct conformal confidence sets let $f_I, f_O:\mathcal{X} \rightarrow \mathcal{X}$ be inner and outer transformation functions and for each $1\leq i \leq n +1 $, let $\tau_i = \max_{v \in \mathcal{V}: Y_i(v) = 0} f_I(s(X_i), v)$ and $\gamma_i = \max_{v \in \mathcal{V}: Y_i(v) = 1} f_O(-s(X_i), v)$  be the maxima of the function transformed scores over the areas at which the true labels equal 0 and 1 respectively. We will require the following assumption on the scores and the transformation functions.
\begin{assumption}\label{ass:indep}
	(Independence of scores) $(X_i, Y_i)_{i = 1}^{n+1}$ is independent of the functions $s, f_O, f_I$. 
\end{assumption}

Given this we construct confidence sets as follows.
\begin{theorem}\label{thm:inner}
	(Marginal inner set)
	Under Assumptions \ref{ass:ex} and \ref{ass:indep}, given $\alpha_1 \in (0,1)$, let 
	\begin{equation*}
		\lambda_I(\alpha_1) = \inf\left\lbrace \lambda: \frac{1}{n} \sum_{i = 1}^n 1\left[ \tau_i\leq \lambda \right] \geq \frac{\lceil (1-\alpha_1)(n+1) \rceil}{n}\right\rbrace,
	\end{equation*}
%	be the upper $\alpha_1$ quantile of $(\tau_i)_{i = 1}^n$
	and define $I(X) = \lbrace v \in \mathcal{V}: f_I(s(X), v) >\lambda_I(\alpha_2)  \rbrace $. Then,
	\begin{equation}\label{eq:probstat}
		\mathbb{P}\left( I(X_{n+1}) \subseteq\lbrace v\in \mathcal{V}: Y_{n+1}(v) = 1 \rbrace \right) \geq 1 - \alpha_1.
	\end{equation}
\end{theorem}
\begin{proof}
	Under Assumptions \ref{ass:ex} and \ref{ass:indep}, exchangeability of the image pairs implies exchangeability of the sequence $(\tau_i)_{i = 1}^{n+1}$. In particular, as $\lambda_I(\alpha_1)$ is the upper $\alpha_1$ quantile of the distribution of $(\tau_i)_{i = 1}^{n} \cup \lbrace \infty \rbrace $ by Lemma 1 of \cite{Tibshirani2019}, it follows that 
	\begin{equation*}
	\mathbb{P}\left(\tau_{n+1} \leq \lambda_I(\alpha_1) \right) \geq 1 - \alpha_1. 
	\end{equation*}
	Now consider the event that $\tau_{n+1}\leq \lambda_I(\alpha)$. On this event, $ f_I(s(X_{n+1}),v) \leq \lambda_I(\alpha) $
	for all $v \in \mathcal{V}$ such that $Y_{n+1}(v) = 0$. As such, given $u \in \mathcal{V}$ such that $ f_I(s(X_{n+1}), u) > \lambda_I(\alpha) $, we must have $Y_{n+1}(u) = 1$ so it follows that $I(X_{n+1}) \subseteq \lbrace v\in \mathcal{V}: Y_{n+1}(v) = 1 \rbrace  $ and in particular that 
	\begin{equation*}
	\mathbb{P}\left( I(X_{n+1}) \subseteq \lbrace v\in \mathcal{V}: Y_{n+1}(v) = 1 \rbrace  \right) \geq \mathbb{P}\left(\tau_{n+1} \leq \lambda_I(\alpha_1) \right) \geq 1 - \alpha_1. 
\end{equation*}
\end{proof}
\noindent For the outer set we have the following analogous result.
\begin{theorem}\label{thm:outer}
	(Marginal outer set)
	Under Assumptions \ref{ass:ex} and \ref{ass:indep}, given $\alpha_2 \in (0,1)$, let 
	\begin{equation*}
		\lambda_O({\alpha_2})= \inf\left\lbrace \lambda: \frac{1}{n} \sum_{i = 1}^n 1\left[ \gamma_i\leq \lambda \right] \geq \frac{\lceil (1-\alpha_2)(n+1) \rceil}{n} \right\rbrace,
	\end{equation*}
%	be the upper $\alpha_2$ quantile of $(\gamma_i)_{i = 1}^n$
	and define $O(X) = \lbrace v \in \mathcal{V}: f_O(-s(X), v) \leq \lambda_O(\alpha_2)  \rbrace $. Then,
	\begin{equation}\label{eq:probstat}
		\mathbb{P}\left( \lbrace v\in \mathcal{V}: Y_{n+1}(v) = 1 \rbrace \subseteq O(X_{n+1}) \right) \geq 1 - \alpha_2.
	\end{equation}
\end{theorem}
\begin{proof}
	Arguing as in the proof of Theorem \ref{thm:inner}, it follows that $\mathbb{P}\left(\gamma_{n+1} \leq \lambda_O(\alpha_2) \right) \geq 1 - \alpha_2.$
	Now on the event that $\gamma_{n+1}\leq \lambda_O(\alpha_2)$ we have $ f_O(-s(X_{n+1},v)) \leq \lambda_O(\alpha_2) $ for all $v \in \mathcal{V}$ such that $Y_{n+1}(v) = 1$. As such, given $u \in \mathcal{V}$ such that $ f_O(-s(X_{n+1},u)) > \lambda_I(\alpha) $, we must have $Y_{n+1}(u) = 0$ and so $	O(X)^C  \subseteq \lbrace v\in \mathcal{V}: Y(v) = 0 \rbrace  $. The result then follows as above.
\end{proof}
%\noindent The proof of Theorem \ref{thm:outer} follows that of Theorem \ref{thm:inner} and is thus omitted. 
\begin{remark}\label{rmk:max}
	We have used the maximum over the transformed scores in order to combine score information on and off the ground truth masks. The maximum is a natural combination function in imaging and is commonly used in the context of multiple testing \citep{Worsley1992}. However the theory above is valid for any increasing combination function. We show this in Appendix \ref{A:CF} where we establish generalized versions of these results.
\end{remark}
\begin{remark}
	Inner and outer coverage can also be viewed as a special case of conformal risk control with an appropriate choice of loss function. We can thus alternatively establish coverage results as a corollary to risk control, see Appendix \ref{risk2con} for details. This amounts to an alternative proof of the results as the proof of the validity of risk control is different though still strongly relies on exchangeability.
\end{remark}
%\begin{remark}
%	Importantly the coverage of the sets $U_M(X)$ and $V_M(X)$ is not jointly valid and so when using these results the choice of inner versus outer set must be made in advance.
%\end{remark}

%\subsection{Confidence sets for connected components}

%\subsection{Full conformal confidence sets}
%We have so far assumed that we have a calibration dataset available, separate from the training data used to contruct the score function, on which we can learn cutoffs and use them to provide conformal confidence sets, using split conformal prediction. As an alternative, we could instead use full conformal prediction in which the entire dataset is used to both train the model and to provide conformal uncertainty. 
%
%To do so let $s_{}$
%
%\begin{remark}
%	Full conformal confidence sets come with the same drawbacks as full conformal inference. In particular they can be very computationally expensive to generate because they require retraining the model for each XXX. As a result, this approach does not scale well when the dataset is large and will often not be practical.
%\end{remark}

\subsection{Joint confidence sets}\label{SS:joint}
Instead of focusing on marginal control one can instead spend all of the $\alpha$ available to construct sets which have a joint probabilistic guarantees. This gain comes at the expense of a loss of precision. The simplest means of constructing jointly valid confidence sets is via the marginal sets themselves.
\begin{corollary}\label{cor:weighting}
	(Joint from marginal) Assume Assumptions \ref{ass:ex} and \ref{ass:indep} hold and given $\alpha \in (0,1)$ and $\alpha_1, \alpha_2 \in (0,1)$ such that $\alpha_1 + \alpha_2 \leq \alpha$, define $I(X)$ and  $O(X)$ as in Theorems \ref{thm:inner} and \ref{thm:outer}. Then 
	\begin{equation}
		\mathbb{P}\left( I(X_{n+1}) \subseteq \lbrace v\in \mathcal{V}: Y_{n+1}(v) = 1 \rbrace \subseteq O(X_{n+1})  \right) \geq  \frac{\lceil (1-\alpha)(n+1) \rceil}{n}. 
	\end{equation}
\end{corollary}
Alternatively joint control can be obtained using the joint distribution of the maxima of the logit scores as follows.
\begin{theorem}\label{thm:joint}
	(Joint coverage) Assume that Assumption \ref{ass:ex} and \ref{ass:indep}  hold. Given $\alpha \in (0,1)$, define 
	\begin{equation*}
		\lambda(\alpha) = \inf\left\lbrace \lambda: \frac{1}{n} \sum_{i = 1}^n 1\left[ \max(\tau_i, \gamma_i) \leq \lambda \right] \geq 1-\alpha \right\rbrace.
	\end{equation*}
% 	be the upper $\alpha$-quantile of the distribution of $\max(\tau_i, \gamma_i)$ over $1 \leq i \leq n$.\\
 Let $O(X) = \lbrace v \in \mathcal{V}: f_O(-s(X,v)) \leq \lambda(\alpha) \rbrace $ and $I(X) = \lbrace v \in \mathcal{V}: f_I(s(X,v)) >	\lambda(\alpha) \rbrace $. Then,
\begin{equation}\label{eq:probstat}
	\mathbb{P}\left( I(X_{n+1}) \subseteq \lbrace v\in \mathcal{V}: Y(v) = 1 \rbrace \subseteq O(X_{n+1}) \right) \geq 1 - \alpha.
\end{equation}
\end{theorem}
\begin{proof}
	Exchangeability of the image pairs implies exchangeability of the sequence $(\tau_i, \gamma_i)_{i = 1}^{n+1}$. Moreover on the event that $\max(\tau_{n+1}, \gamma_{n+1}) \leq \lambda(\alpha)$ we have $\tau_{n+1} \leq \lambda(\alpha)$ and $\gamma_{n+1} \leq \lambda(\alpha)$ so the result follows via a proof similar to that of Theorem \ref{thm:inner}.
\end{proof}

\begin{remark}
	The advantage of Corollary \ref{cor:weighting} is that the resulting inner and outer sets provide pivotal inference - not favouring one side or the other - which can be important when the distribution of the score function is asymmetric. Moreover the levels $\alpha_1$ and $\alpha_2$ can be used to provide a greater weight to either inner or outer sets whilst maintaining joint coverage. Theorem \ref{thm:joint} may instead be useful when there are strong levels of dependence between $\tau_1$ and $\gamma_1$. However, when this dependence is low, scale differences in the scores can lead to a lack of pivotality. This can be improved by appropriate choices of the score transformations $f_I$ and $f_O$ however in practice it may be simpler to construct joint sets using Corollary \ref{cor:weighting}. 
\end{remark}

%Typically in our applications, $X_{n+1}$ will observed with $Y$ unknown.
%
%%%%
% $c: \mathcal{X} \times \mathcal{V} \rightarrow \mathbb{R} $ such that given  and letting $I(X) = \lbrace v \in \mathcal{V}: c(X,v) = 1\rbrace$, we have
%\begin{equation*}
%	\mathbb{P}\left( Y(v) = 1 \text{ for all } v \in I(X) \right) \geq 1 - \alpha.
%\end{equation*}
%This corresponds to controlling  $\mathbb{P}\left( Y(v) = 0 \text{ for all } v \in I(X) \right) $, i.e. the probabilty of making an error, to a level $\alpha.$ This error rate is analogous to the familywise error rate from the multiple testing setting, an observation that allows us to control it using the distribution of the maximum in the spirit of Westphal-Young. 
%
%To do so, let $T_i = \max_{v \in \mathcal{V}: Y_i(v) = 0} s(X_i,v)$ and define
%\begin{equation*}
%	\lambda_{\alpha} = \inf\left\lbrace \lambda: \frac{1}{n} \sum_{i = 1}^n 1\left[ T_i \leq \lambda \right] \geq \alpha \right\rbrace.
%\end{equation*}
%be the upper $\alpha$-quantile of the distribution of the maximum of the score function of the observed image over the areas at which the true label is equal to 0. Then define the classifier, $c: \mathcal{X} \times \mathcal{V}$ such that
%\begin{equation*}
%	c(X, v) = 1[s(X,v)> \lambda_{\alpha}].
%\end{equation*}
%\begin{theorem}
%	Given $(X,Y) \sim \mathcal{D}$ independent of $(X_i, Y_i)_{i = 1}^n$, we have
%	\begin{equation*}
%		\mathbb{P}\left( Y(v) = 1 \text{ for all } v \in I(X) \right) \geq 1 - \alpha.
%	\end{equation*}
%\end{theorem}
%\begin{proof}
%	Suppose that $Y(v) = 0$ for some $v \in I(X)$, then it follows that $s(X,v) > \lambda_\alpha$ and conversely. Thus the event $\lbrace Y(v) = 0 \text{ for some } v \in I(X) \rbrace$ occurs if and only if $\max_{v \in \mathcal{V}: Y(v) = 0} s(X,v) >  \lambda_\alpha$. Let $T_{n+1} = \max_{v \in \mathcal{V}: Y(v) = 0} s(X,v)$. Then the vector $(T_1, \dots, T_{n+1})$ is exchangeable, so arguing as in XXX, it follows that $T_{n+1}$ is equally to lie between (or before/after) the values $T_1, \dots, T_n$. As such 
%	$\mathbb{P}\left( T_{n+1} > \lambda_{\alpha}\right) \leq \alpha$
%	and the result follows.
%\end{proof}

\subsection{Better segmentors provide more precise conformal confidence sets}
Given two real random variables, $A$ and $B$ write $ A \succeq B$ to indicate that $\mathbb{P}\left( A > t \right) \geq \mathbb{P}\left( B > t \right)$ for all $t \in \mathbb{R}$. Then we have the following result. 
\begin{theorem}
	Suppose that $(X_i, Y_i)_{i = 1}^{n+1}$ is an i.i.d. sequence, and let $s, t: \mathcal{V} \rightarrow \mathbb{R}$ be two score functions. Assume that 
	$\max_{v \in \mathcal{V}: Y_1(v) = 0} s_v(X_{1}) \succeq \max_{v \in \mathcal{V}: Y_1(v) = 0} s_v(X_{1}) $
\end{theorem}

\subsection{Optimizing score transformations}
%\subsubsection{Setting aside a learning dataset}
The choice of score transformations $f_I$ and $f_O$ is extremely important and can have a large impact on the size of the conformal confidence sets. The best choice depends on both the distribution of the data and on the nature of the output of the trained segmentor used to calculate the scores. We thus recommend setting aside a learning dataset independent from both the calibration dataset, used to compute the conformal thresholds, and the test dataset. This approach was used in \cite{Sun2024} to learn the best copula transformation for combining dependent data streams.

In order to make efficient use of the data available, the learning dataset can in fact contain some or all of the data used to train the image segmentor. This data is assumed to be independent of the calibration and test data and so can be used to learn the best score transformations without compromising validity . The advantage of doing so is that less additional data needs to be set aside or collected for the purposes of learning a score function. Moreover it allows for additional data to be used to train the model resulting in better segmentation performance. The disadvantage is that machine learning models typically overfit their training data meaning that certain score functions may appear to perform better on this data than they do in practice. The choice of whether to include training data in the learning dataset thus depends on the quantity of data available and the quality of the segmentation model.

A score transformation that we will make particular use of in Section \ref{SS:res} is based on the distance transformation which we define as follows. Given a set $\mathcal{A} \subseteq \mathcal{V}$, let $E(\mathcal{A})$ be the set of points on the boundary of $\mathcal{A}$ obtained using the marching squares algorithm \citep{Maple2003}. Given a distance metric $\rho$ we define the distance transformation $d_{\mathcal{A}, \rho}:\mathcal{X} \rightarrow \mathcal{X}$, which sends $X\in \mathcal{X}$ and $v\in \mathcal{V}$ to
\begin{equation*}
	d_{\mathcal{A}, \rho}(X, v) = \text{sign}_\mathcal{A}(v)\min\lbrace \rho(v, e): e \in E(\mathcal{A})\rbrace, 
\end{equation*}
where $ \text{sign}_\mathcal{A}(v) = 1 $ if $v\in \mathcal{A}$ and equals $0$ otherwise. The function $d_{\mathcal{A}, \rho}$ is an adapation of the distance transform of \cite{Borgefors1986} which provides positive values within the set $\mathcal{A}$ and negative values outside of $\mathcal{A}$.

\subsection{Constructing confidence sets from bounding boxes}
Existing work on conformal confidence sets which aim to provide coverage of the entire ground truth mask with a given probability has primarily focused on bounding boxes, see \citep{De2022, Andeol2023, Mukama2024}. These papers adjust for multiple comparisons over the 4 edges of the bounding box, doing so conformally by comparing the distance between the predicted bounding box and the bounding box of the ground truth mask. These approaches aggregrate the predicted bounding boxes over all objects within all of the calibration images, often combining multiple bounding boxes per image. However, as observed in Section 5 of \cite{De2022}, doing so violates exchangeability which needed for valid conformal inference, as there is dependence between the objects within each image. These papers do not provide formal proofs and their theoretical validity is thus unclear.

% particular CITE relies on the results of CITE to establish validity however these results do not directly apply in the bounding box setting. This is because, while CITE shows the validity of conformal inference over multiple depenedent inferences but it assumes a fixed number of these inferences. Instead the number of true and predicted bounding boxes in a given image can vary so the result of CITE does not apply.
In order to provide a more formal justification of bounding box methods we establish the validity of an adapted version of the max-additive bounding box method of \cite{Andeol2023} as a corollary to our results, see Appendix \ref{AA:BBtheory}. We compare to this approach in our experiments below. Targetting bounding boxes does not directly target the mask itself and so the resulting confidence sets are typically conservative.

\section{Application to Polpys tumor segmentation}\label{SS:res}
In order to illustrate and validate our approach we consider the problem of polpys tumor segmentation. To do so we use the same dataset as in \cite{Angelopoulos2022} in which 1798 poplys images, with available ground truth masks were combined from 5 open-source datasets (published in \cite{KVASIR2017}, \cite{Hyperkvasir2020} \cite{Bernal2012}, \cite{Silva2014}). Logit scores were obtained for this data using the PraNet model \cite{PraNet2020}, which is based on the Unet architecture CITE CHECK! 

\subsection{Choosing a score transformation}
In order to optimize the size of our confidence sets we set aside 298 of the 1798 polpys images to form a learning dataset on which to choose the best score transformations. Importantly as the learning dataset is independent of the remaining 1500 images set-aside, we can study it as much as we like without compromising the validity of the follow-up analyses in Sections \ref{SS:val}, 

The score transformations we considered were the identity (after softmax transformation), distance transformations of the predicted masks and bounding box scores. 


The PraNet scores for several typical examples are shown, after applying these transformations, in Figure XXX.  From these we see that PraNet assigns a high softmax score to the polpys regions which decreases in the regions directly around the  boundary of the tumor before returning to a higher level away from the polpys. This results in tight inner sets but large outer sets as the model struggles to identify where the tumor ends. 

A further 10 examples are shown in Appendix XXX. 

Based on the images set aside for alpha weighting we decided to use $\alpha_1 = 0.02$ and $\alpha_2 = 0.08$ to ensure a joint coverage of $90\%$. This ratio was chosen in light of the fact that in this data identifying where a given tumor ends appears to be more challenging than identifying pixels where we are sure that there is a tumor. For comparison we also present the results of an equal weighting scheme.


\begin{figure}
		\centering
		\includegraphics[width=0.3\textwidth]{../figures/learning/origscores.png}
		\includegraphics[width=0.3\textwidth]{../figures/learning/distscores.png}
		\label{scorehists}
\end{figure}
From the histograms in Figure \ref{scorehists} we can see that thresholding the scores at the inner threshold captures most of the data. However this is not the case for the outer threshold. From Figure XXX we can see that confidence sets based on the original scores struggle to identify where the tumor ends, resulting in very large sets. 

\begin{figure}
%	\centering
\begin{center}
	\includegraphics[width=0.24\textwidth]{../figures/learning/scores/903.png}
		\includegraphics[width=0.24\textwidth]{../figures/learning/score_surf/903.png}	\includegraphics[width=0.24\textwidth]{../figures/learning/dist_surf/903.png}
		\includegraphics[width=0.24\textwidth]{../figures/learning/dist_bt_surf/903.png}\\
		\includegraphics[width=0.24\textwidth]{../figures/learning/images/903.png}
	\includegraphics[width=0.24\textwidth]{../figures/learning/score_crs_marginal90/903.png}
	\includegraphics[width=0.24\textwidth]{../figures/learning/dist_crs_marginal90/903.png}
	\includegraphics[width=0.24\textwidth]{../figures/learning/dist_bt_crs_marginal90/903.png}\\
\vspace{0.5cm}
		\includegraphics[width=0.24\textwidth]{../figures/learning/scores/362.png}
	\includegraphics[width=0.24\textwidth]{../figures/learning/score_surf/362.png}	\includegraphics[width=0.24\textwidth]{../figures/learning/dist_surf/362.png}
	\includegraphics[width=0.24\textwidth]{../figures/learning/dist_bt_surf/362.png}\\
	\includegraphics[width=0.24\textwidth]{../figures/learning/images/362.png}
	\includegraphics[width=0.24\textwidth]{../figures/learning/score_crs_marginal90/362.png}
	\includegraphics[width=0.24\textwidth]{../figures/learning/dist_crs_marginal90/362.png}
	\includegraphics[width=0.24\textwidth]{../figures/learning/dist_bt_crs_marginal90/362.png}
\end{center}
	\caption{Illustrating the performance of the different score transformations on the learning dataset. We display 2 example tumors and present the results of each in 8 panels. These panels are as follows. Bottom right: the original image of the polpys tumor. Top Left: an intensity plot of the scores obtained from PraNet with purple/yellow indicating areas of lower/higher assigned probability. For the remaining panels, 3 different score transformations are shown which from left to right are the original scores, distance transformed scores and bounding box scores. In each of the panels on the top row a surface plot of the transformed PraNet scores is shown, along with the marginal conformal thresholds which are used to obtain the marginal 90\% inner and outer sets.  These thresholds are illustrated via red and blue planes respectively and are obtained over the learning dataset. The panels on the bottom show the corresponding conformal confidence sets. Here the inner set is shown in red, plotted over the ground truth mask of the polyps, shown in yellow, plotted over the outer set which is shown in blue. The outer set contains the ground truth mask which contains the inner set in all examples. From these figures we see that the original scores provide tight inner confidence sets and the distance transformed scores instead provide tight outer confidence sets. The conclusion from the learning dataset is therefore that it makes sense to combine these two score transformations.}
	\label{fig:learning}
\end{figure}


%\subsection{Tumor detection}
%\begin{figure}[h!]
%	\centering
%	\includegraphics[width=\textwidth]{tumorfwerimage.png}
%	\caption{Examples}
%	\label{fig:enter-label}
%\end{figure

%\subsection{}
\subsection{Illustrating the performance of conformal confidence sets}\label{SS:val}
Based on the results of the learning dataset we decided to combine the best of the approaches for the inner and outer sets respectively, taking $f_I$ to be the softmax transformation and $f_O$ to be the distance transformation of the predicted mask.

We divide the 1500 images at random into 500 for conformal calibration, and 1000 for validation. The resulting conformal confidence sets for this data are shown in the second row of Figure \ref{fig:polpys}. For comparison we have also shown the sets obtained based on the untransformed softmax scores in the top row. From this figure we see that the method, using the transformed scores, effectively delineates polyp regions. Inner sets are plotted in red and the outer sets are shown in blue. The ground truth mask for each polpys is shown in yellow and can be compared to the original images. In each of the examples considered the ground truth mask is bounded from within by the inner set and from without by the outer set. 

\begin{figure}
	\begin{subfigure}{0.19\textwidth}
		\centering
		\includegraphics[width=\textwidth]{../figures/val_images/15.png}
		\label{fig:1}
	\end{subfigure}
	\begin{subfigure}{0.19\textwidth}
		\centering
		\includegraphics[width=\textwidth]{../figures/val_images/114.png}
		\label{fig:1}
	\end{subfigure}
	\begin{subfigure}{0.19\textwidth}
		\centering
		\includegraphics[width=\textwidth]{../figures/val_images/61.png}
		\label{fig:1}
	\end{subfigure}
	\begin{subfigure}{0.19\textwidth}
		\centering
		\includegraphics[width=\textwidth]{../figures/val_images/76.png}
		\label{fig:1}
	\end{subfigure}
	\begin{subfigure}{0.19\textwidth}
		\centering
		\includegraphics[width=\textwidth]{../figures/val_images/87.png}
		\label{fig:1}
	\end{subfigure}
		\vspace{-0.4cm}
	\\
		\begin{subfigure}{0.19\textwidth}
		\centering
		\includegraphics[width=\textwidth]{../figures/val_crs_90_orig/15.png}
		\label{fig:1}
	\end{subfigure}
	\begin{subfigure}{0.19\textwidth}
		\centering
		\includegraphics[width=\textwidth]{../figures/val_crs_90_orig/114.png}
		\label{fig:1}
	\end{subfigure}
	\begin{subfigure}{0.19\textwidth}
		\centering
		\includegraphics[width=\textwidth]{../figures/val_crs_90_orig/61.png}
		\label{fig:1}
	\end{subfigure}
	\begin{subfigure}{0.19\textwidth}
		\centering
		\includegraphics[width=\textwidth]{../figures/val_crs_90_orig/76.png}
		\label{fig:1}
	\end{subfigure}
	\begin{subfigure}{0.19\textwidth}
		\centering
		\includegraphics[width=\textwidth]{../figures/val_crs_90_orig/87.png}
		\label{fig:1}
	\end{subfigure}
	\vspace{-0.4cm}
	\\
	\begin{subfigure}{0.19\textwidth}
		\centering
		\includegraphics[width=\textwidth]{../figures/val_crs_90_distmix/15.png}
		\label{fig:1}
	\end{subfigure}
	\begin{subfigure}{0.19\textwidth}
		\centering
		\includegraphics[width=\textwidth]{../figures/val_crs_90_distmix/114.png}
		\label{fig:1}
	\end{subfigure}
	\begin{subfigure}{0.19\textwidth}
		\centering
		\includegraphics[width=\textwidth]{../figures/val_crs_90_distmix/61.png}
		\label{fig:1}
	\end{subfigure}
	\begin{subfigure}{0.19\textwidth}
		\centering
		\includegraphics[width=\textwidth]{../figures/val_crs_90_distmix/76.png}
		\label{fig:1}
	\end{subfigure}
	\begin{subfigure}{0.19\textwidth}
		\centering
		\includegraphics[width=\textwidth]{../figures/val_crs_90_distmix/87.png}
		\label{fig:1}
	\end{subfigure}
	\label{fig:grid}
	\caption{Conformal confidence sets for the polyps data. The bottom row shows the original endoscopic images with visible polyps. The top two rows present the conformal confidence sets, with the ground truth masks shown in yellow. The inner sets and outer sets are shown in red and blue respectively. The top row illustrates the sets which arise when using the original scores. Instead the middle show the resulting sets when $f_O$ is given by the distance transformation of the predicted polpys mask. The figure shows the benefit of transforming the score function and illustrates the method's effectiveness in accurately identifying polyp regions whilst providing informative spatial uncertainty bounds.}\label{fig:polpys}
\end{figure}


The inner sets are shown in red and represent regions where we can have high confidence of the presence of polyps. The outer sets are shown in blue and represent regions in which the polpys may be.

These results show that we can provide informative confidence bounds for the location of the polpys and allow us to use the PraNet segmentation model with uncertainty guarantees. They also illustrate the limitations of the model which is essential for applications. Larger uncertainty bounds may require specialist follow-up in order to be certain about the true extent of the observed tumor. Improved uncertainty quantification would require an improved segmentation model. 

More precise results can be obtained at the expense of probabilistic guarantees, see Figure XXX. A trade off must be made between precision and confidence and this can also be determined in advance based on the learning dataset. The approach of CITE controls the empirical false negative risk yielding additional precision but at the cost of coverage as shown in Figure XXX. 

\subsection{Measuring the coverge rate}\label{SS:cov}
In this section we run validations to evaluate the false coverage rate of our approach. To do so we take the set aside 1500 images and run 1000 validations, in each validation dividing the data into equally sized calibration and test sets of 750 images. In each division we calculate the conformal confidence sets using the above approaches and evaluate the coverage rate on the test dataset. We average over all validations and present the results in Figure XXX. Histograms for the $90\%$ coverage obtained over each validation run are shown in Figure \ref{fig:valhist}.

 In this Figure we also compare to the coverage attained by using Conformal Risk control \cite{}. We can see that conformal risk control can have highly inflated error rates - this is because it is designed to control the expected proportion of discoveries not cover the tumors. The results indicate the trade-off that must be made when choosing between the methodss, i.e. whilst risk control can provide meaningful inference CITE it comes with a cost in terms of under coverage. Instead, in this setting, conformal confidence sets provide informative segmentation bounds (as illustrated in Section \ref{SS:val}) and come with strong coverage guarantees. 
\begin{figure}
	\begin{center}
		\includegraphics[width=0.4\textwidth]{../figures/validation/inner_coverage.pdf}
		\quad\quad
		\includegraphics[width=0.4\textwidth]{../figures/validation/outer_coverage.pdf}
	\end{center}
	\caption{False coverage levels of the inner and outer sets averaged over 1000 validations for the original, distance transformed (DT) and bounding box (BB) scores.}\label{fig:coverage}
\end{figure}

%\begin{figure}
%	\includegraphics[width=0.32\textwidth]{../figures/validation/inner_coverage.pdf}
%	\includegraphics[width=0.32\textwidth]{../figures/validation/outer_coverage.pdf}
%	\caption{False coverage levels of the inner and outer sets averaged over 1000 validations for the original, distance transformed (DT) and bounding box (BB) scores.}\label{fig:coverage}
%\end{figure}
%	\quad
%\includegraphics[width=0.28\textwidth]{../figures/validation/val_hist.pdf}

\subsection{Comparing the efficiency of the bounds}
\begin{figure}
	\begin{center}
			\includegraphics[width=0.45\textwidth]{../figures/efficiency/inner_ratio.pdf}
			\quad\quad
		\includegraphics[width=0.45\textwidth]{../figures/efficiency/outer_ratio.pdf}
	\end{center}
	\caption{Measuring the efficiency of the bound using the ratio of the diameter of the coverage set to the diameter of the true tumor mask The closer the ratio is to one the better. Higher coverage rates lead to a lower efficiency. The original scores provide the most efficient inner sets and the distance transformed scores provide the most efficient outer sets.}\label{fig:efficiency}
\end{figure}

\begin{figure}
	\begin{center}
		\includegraphics[width=0.32\textwidth]{../figures/validation/val_hist_orig_inner.pdf}
		\includegraphics[width=0.32\textwidth]{../figures/validation/val_hist_dt_inner.pdf}\\
		\includegraphics[width=0.32\textwidth]{../figures/validation/val_hist_orig_outer.pdf}
		\includegraphics[width=0.32\textwidth]{../figures/validation/val_hist_dt_outer.pdf}
	\end{center}
	\caption{Histograms of the coverage rates obtained across each of the validation resamples for 90\% inner and outer marginal confidence sets. We plot the results for the original scores, distance transformed scores (DT) and boundary box scores (BB) from left to right.}\label{fig:valhist}
\end{figure}

\begin{figure}
	\begin{center}
			\includegraphics[width=0.46\textwidth]{../figures/efficiency/inner_proportion.pdf}
			\quad\quad
		\includegraphics[width=0.45\textwidth]{../figures/efficiency/outer_proportion.pdf}
	\end{center}
	\caption{Measuring the proportion of the entire image which is under/over covered by the respective confidence sets. Left: proportion of the image which lies within the true mask but outside of the inner set. Middle: proportion of the image which lies within the confidence set but outside of the true mask. For both a lower proportion corresponds to increased precision. }\label{fig:efficiency2}
\end{figure}

\subsection{Improving risk control using transformed scores}
Risk control can also benefit  
 
%\subsection{Application to Melanoma segmentation}

%\subsection{Melanoma Lesion Segmentation}

%\subsection{Melanoma Segmentation}
