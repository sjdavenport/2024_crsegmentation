In this work, we have developed conformal confidence sets which offer probabilistic guarantees for the output of a black box image segmentation model and provide tight bounds. Our work helps to address the lack of formal uncertainty quantification in the application of deep neural networks to medical imaging which has limited the reliability and adoption of these models in practice. \nt{Confidence sets provide informative spatial bounds on the expected output and ensure that we are not overconfident about our model predictions.}
%We have here established validity guarantees and additionally showed that these can be used to theoretically justify a modified version of the max-additive bounding box based method of \cite{Andeol2023}. 

The use of the distance transformed scores \nt{was important in providing tight outer confidence bounds in all applications considered} as the original neural network is by itself unable to reliably determine where the true masks end with certainty. The distance transformation penalizes regions away from the predicted mask, allowing the true mask to be distinguished from the background. In other datasets and model settings, other transformations may be appropriate. We saw for instance that smoothing the scores can be beneficial and allow the model to boost power using spatial information. As such we strongly recommend the use of a learning dataset to learn the best transformation and maximize the precision of the resulting confidence bounds.

The use of improved neural networks which can better separate the scores within and outside the ground truth masks would lead to more precise confidence sets and optimizing this is an important area of research. 

The confidence sets we develop in this paper are related in spirit to work on uncertainty quantification for spatial excursion sets (\cite{chen2017density}, \cite{Bowring2019}, \cite{Mejia2020}). These approaches instead assume that multiple observations from a signal plus noise model are observed and perform inference on the underlying signal rather than prediction. Unlike conformal inference these approaches rely on central limit theorems or distributional assumptions in order to provide spatial confidence regions with asymptotic coverage guarantees. 

\section*{Availability of code}
\vspace{-0.1cm}
Matlab code to implement the methods of this paper and a demo on a downscaled version of the data is available in the supplementary material. The code is very fast: calculating inner and outer thresholds (over the 1000 images in the calibration set) requires approximately 0.03 seconds on the downscaled data on a standard laptop (Apple M3 chip with 16 GB RAM) and 2.64 seconds for the original dataset. 