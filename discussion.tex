In this work, we have developed conformal confidence sets which offer probabilistic guarantees for the output of a black box image segmentation model and provide tight bounds. Our work helps to address the lack of formal uncertainty quantification in the application of deep neural networks to medical imaging which has limited the reliability and adoption of these models in practice. \nt{Confidence sets provide informative spatial bounds on the expected output and ensure that we are not overconfident about our model predictions.}
%We have here established validity guarantees and additionally showed that these can be used to theoretically justify a modified version of the max-additive bounding box based method of \cite{Andeol2023}. 

The use of the distance transformed scores \nt{was important in providing tight outer confidence bounds in all applications considered} as the original neural network is by itself unable to reliably determine where the true masks end with certainty. The distance transformation penalizes regions away from the predicted mask, allowing the true mask to be distinguished from the background. In other datasets and model settings, other transformations may be appropriate. We saw for instance that smoothing the scores can be beneficial and allow the model to boost power using spatial information. As such we strongly recommend the use of a learning dataset to learn the best transformation and maximize the precision of the resulting confidence bounds.

\nt{We have shown (Theorems \ref{thm:distscoreschar} and \ref{thm:distscoreschar2}) that an increase in the quality of the predictions of the image segmentation model leads to more precise confidence sets when using the distance transformed scores. Such a relationship does not hold for the logit scores. This is well illustrated in the brain imaging application, see Figure \ref{fig:brain2}, in which the distance transformed scores allow for very tight uncertainty bands but the confidence sets obtained based on the logit scores are very uninformative. Metrics for each model used are shown in Appendix \ref{metrics} and correspond to the performance of the distance transformed scores in practice.}

The confidence sets we develop in this paper are related in spirit to work on uncertainty quantification for spatial excursion sets (\cite{chen2017density}, \cite{Bowring2019}, \cite{Mejia2020}). These approaches instead assume that multiple observations from a signal plus noise model are observed and perform inference on the underlying signal rather than prediction. Unlike conformal inference these approaches rely on central limit theorems or distributional assumptions in order to provide spatial confidence regions with asymptotic coverage guarantees. 

%\section*{Availability of code}
%\vspace{-0.1cm}
Matlab code to implement the methods of this paper and a demo on a downscaled version of the data is available in the supplementary material. The code is very fast: calculating inner and outer thresholds (over the 1000 images in the calibration set) requires approximately 0.03 seconds on the downscaled polyps data on a standard laptop (Apple M3 chip with 16 GB RAM) and 2.64 seconds for the original polyps dataset. %nt{This fast performance is due to our observation that it is sufficient to rely on quantiles of the maximum scores within and outside the mask, meaning we don't have to rely on binary search to obtain the conformal prediction threshold.}